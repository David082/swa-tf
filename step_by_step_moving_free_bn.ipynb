{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from math import ceil\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "EPOCHS = 50\n",
    "INIT_LR = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "- load `train` and `test` subsets (CIFAR-10)\n",
    "- split `train` into `train` + `valid` (80/20%, stratified split on labels)\n",
    "\n",
    "- create data generators (with `keras.preprocessing.image.ImageDataGenerator`):\n",
    "    - one ImageDataGenerator with data augmentation (horizontal flips, random translations) for train set\n",
    "    - three ImageDataGenerator without data augmentation for train, valid and test subset \n",
    "        - why `train` ? : to fit Batch Norm statistics without augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading CIFAR10 dataset ...\n",
      "\tTRAIN - images (40000, 32, 32, 3) | float32  - labels (40000,) - int32\n",
      "\tVAL - images (10000, 32, 32, 3) | float32  - labels (10000,) - int32\n",
      "\tTEST - images (10000, 32, 32, 3) | float32  - labels (10000,) - int32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"... loading CIFAR10 dataset ...\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                                  test_size=0.2,\n",
    "                                                  stratify=y_train,\n",
    "                                                  random_state=51)\n",
    "# cast samples and labels\n",
    "x_train = x_train.astype(np.float32) / 255.\n",
    "x_val = x_val.astype(np.float32) / 255.\n",
    "x_test = x_test.astype(np.float32) / 255.\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_val = y_val.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "print(\"\\tTRAIN - images {} | {}  - labels {} - {}\".format(x_train.shape, x_train.dtype, y_train.shape, y_train.dtype))\n",
    "print(\"\\tVAL - images {} | {}  - labels {} - {}\".format(x_val.shape, x_val.dtype, y_val.shape, y_val.dtype))\n",
    "print(\"\\tTEST - images {} | {}  - labels {} - {}\\n\".format(x_test.shape, x_test.dtype, y_test.shape, y_test.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_aug = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=5,\n",
    "                                                                height_shift_range=5,\n",
    "                                                                fill_mode='constant',\n",
    "                                                                cval=0.0,\n",
    "                                                                rotation_range=90.,\n",
    "                                                                horizontal_flip=True,\n",
    "                                                                vertical_flip=True)\n",
    "\n",
    "generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# python iterator object that yields augmented samples \n",
    "iterator_train_aug = generator_aug.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "# python iterators object that yields not augmented samples \n",
    "iterator_train = generator.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "iterator_valid = generator.flow(x_val, y_val, batch_size=BATCH_SIZE)\n",
    "iterator_test = generator.flow(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "steps_per_epoch_train = int(ceil(iterator_train.n/BATCH_SIZE))\n",
    "steps_per_epoch_val = int(ceil(iterator_valid.n/BATCH_SIZE))\n",
    "steps_per_epoch_test = int(ceil(iterator_test.n/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : 1\n",
      "x : (16, 32, 32, 3) | float32\n",
      "y : (16,) | int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f66657944a8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test iterator with data augmentation\n",
    "x, y = iterator_train_aug.next()\n",
    "\n",
    "i = 0 \n",
    "img = x[i]*255\n",
    "label = y[i]\n",
    "print(\"label : {}\".format(label))\n",
    "print(\"x : {} | {}\".format(x.shape, x.dtype))\n",
    "print(\"y : {} | {}\".format(y.shape, y.dtype))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now data iterators are ready ! \n",
    "\n",
    "# Build a network with MovingFreeBatchNorm layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moving_free_batch_normalization import moving_free_batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TensorFlow session\n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs: only placeholders (easy to use) !\n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "    # to images\n",
    "    batch_x = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32)\n",
    "    \n",
    "    # to feed labels\n",
    "    batch_y = tf.placeholder(shape=[None, ], dtype=tf.int64)\n",
    "    \n",
    "    # placeholders to set the learning phase (train vs inference)\n",
    "    # this controls the behavior of BN layers \n",
    "    is_training_bn = tf.placeholder(shape=[], dtype=tf.bool)\n",
    "    \n",
    "    # select which statistics (mean, variance) to use in BN layers during inference \n",
    "    # when is_training_bn is False !\n",
    "    use_moving_statistics = tf.placeholder(shape=[], dtype=tf.bool)\n",
    "    \n",
    "    # placeholder for learning rate for learning scheduling \n",
    "    learning_rate = tf.placeholder(shape=[], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network similar to a VGG11 \n",
    "\n",
    "with tf.name_scope('network'):\n",
    "    ######################### 32x32 features per feature maps #########################\n",
    "    x = tf.layers.conv2d(batch_x, filters=64, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2, data_format='channels_last', padding='same')\n",
    "    ###################################################################################\n",
    "\n",
    "    \n",
    "    ######################### 16x16 features per feature maps #########################\n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2, data_format='channels_last', padding='same')\n",
    "    ###################################################################################\n",
    "    \n",
    "    ######################### 8x8 features per feature maps #########################\n",
    "    x = tf.layers.conv2d(x, filters=256, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn, use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.conv2d(x, filters=256, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2, data_format='channels_last', padding='same')\n",
    "    ###################################################################################\n",
    "    \n",
    "    ######################### 4x4 features per feature maps #########################\n",
    "    x = tf.layers.conv2d(x, filters=512, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn, use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.conv2d(x, filters=512, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2, data_format='channels_last', padding='same')\n",
    "    ###################################################################################\n",
    "    \n",
    "    ######################### 2x2 features per feature maps #########################\n",
    "    x = tf.layers.conv2d(x, filters=512, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn, use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.conv2d(x, filters=512, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    ###################################################################################\n",
    "    \n",
    "    ######################### Global Average Pooling #########################\n",
    "    x = tf.reduce_mean(x, axis=[1, 2]) \n",
    "    logits = tf.layers.dense(x, units=10, use_bias=True)\n",
    "    ###################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d/bias:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization/beta:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_1/bias:0' shape=(128,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_1/gamma:0' shape=(128,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_1/beta:0' shape=(128,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_2/bias:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_2/gamma:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_2/beta:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_3/bias:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_3/gamma:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_3/beta:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_4/bias:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_4/gamma:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_4/beta:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_5/bias:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_5/gamma:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_5/beta:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_6/bias:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_6/gamma:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_6/beta:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_7/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_7/bias:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_7/gamma:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_7/beta:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'dense/kernel:0' shape=(512, 10) dtype=float32_ref>,\n",
      " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "model_vars = tf.trainable_variables()\n",
    "pprint(model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'network/moving_free_batch_normalization/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_1/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_1/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_2/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_2/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_3/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_3/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_4/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_4/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_5/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_5/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_6/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_6/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_7/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_7/AssignMovingAvg_1' type=AssignSub>]\n",
      "[<tf.Tensor 'network/moving_free_batch_normalization/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_1/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_2/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_3/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_4/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_5/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_6/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_7/AssignAdd:0' shape=() dtype=float32_ref>]\n",
      "[<tf.Operation 'network/moving_free_batch_normalization/ResetBatchNormStats' type=NoOp>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_1/ResetBatchNormStats' type=NoOp>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_2/ResetBatchNormStats' type=NoOp>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_3/ResetBatchNormStats' type=NoOp>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_4/ResetBatchNormStats' type=NoOp>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_5/ResetBatchNormStats' type=NoOp>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_6/ResetBatchNormStats' type=NoOp>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_7/ResetBatchNormStats' type=NoOp>]\n"
     ]
    }
   ],
   "source": [
    "# operations to update moving averages in batch norm layers\n",
    "# to run before updating weights ! (with tf.control_dependencies())\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "# these operations are new, specific to MovingFreeBatchNorm layers.\n",
    "# operations to updates (mean, variance, n) in batch norm layers \n",
    "update_bn_ops = tf.get_collection('UPDATE_BN_OPS')\n",
    "# operations to reset (mean, variance, n) to zero \n",
    "reset_bn_ops = tf.get_collection('RESET_BN_OPS')\n",
    "\n",
    "pprint(update_ops)\n",
    "pprint(update_bn_ops)\n",
    "pprint(reset_bn_ops)\n",
    "\n",
    "# group these operations\n",
    "update_ops = tf.group(*update_ops)\n",
    "update_bn_ops = tf.group(*update_bn_ops)\n",
    "reset_bn_ops = tf.group(*reset_bn_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add loss and accuracy \n",
    "with tf.name_scope('loss'):\n",
    "    loss_tf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                                            labels=batch_y))\n",
    "    acc_tf = tf.reduce_mean(tf.cast(tf.equal(batch_y, tf.argmax(logits, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization with SGD x Momentum\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "    \n",
    "    # even with MovingFreeBatchNorm we can update the moving statistics\n",
    "    with tf.control_dependencies([update_ops,]):\n",
    "        train_op = opt.minimize(loss_tf, var_list=model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize all parameters \n",
    "global_init_op = tf.global_variables_initializer()\n",
    "sess.run(global_init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant learning rate\n",
    "def get_learning_rate(step, epoch, steps_per_epoch_train):\n",
    "    return INIT_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch traninig \n",
    "- create a function to fit statistics with train subset\n",
    "- create a function to run inference on [train/]val/test subsets (with/without moving statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_bn_statistics():\n",
    "    # reset new BN statistics\n",
    "    sess.run(reset_bn_ops)\n",
    "    \n",
    "    # when updating, set is_training_bn=True\n",
    "    feed_dict = {is_training_bn: True, use_moving_statistics: True}\n",
    "    for _ in range(steps_per_epoch_train):\n",
    "        # use sample from the train set, without data augmentation\n",
    "        x, y = iterator_train.next()\n",
    "        feed_dict[batch_x] = x\n",
    "        sess.run(update_bn_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(iterator, with_moving_statistics=True):\n",
    "    \n",
    "    feed_dict = {is_training_bn: False,\n",
    "                 use_moving_statistics: with_moving_statistics}\n",
    "    \n",
    "    all_acc = []\n",
    "    all_loss = []\n",
    "    nb_steps = int(ceil(iterator.n/BATCH_SIZE))\n",
    "    \n",
    "    for _ in range(nb_steps):\n",
    "        x, y = iterator.next()\n",
    "        feed_dict[batch_x] = x\n",
    "        feed_dict[batch_y] = y\n",
    "        acc_v, loss_v = sess.run([acc_tf, loss_tf], feed_dict=feed_dict)\n",
    "        all_acc.append(acc_v)\n",
    "        all_loss.append(loss_v)\n",
    "    \n",
    "    return np.mean(all_acc), np.mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test your random model ? \n",
    "acc, loss = inference(iterator_valid, with_moving_statistics=True)\n",
    "print(\"Random model : acc={:.5f}   loss={:.5f}\".format(acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# now fit batch norm statistics and make inference again \n",
    "fit_bn_statistics()\n",
    "acc, loss = inference(iterator_valid, with_moving_statistics=False)\n",
    "print(\"Random model : acc={:.5f}   loss={:.5f}\".format(acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "step = 0\n",
    "start = time()\n",
    "\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "\n",
    "acc_val = []\n",
    "loss_val = []\n",
    "\n",
    "acc_val_bn = []\n",
    "loss_val_bn = []\n",
    "\n",
    "feed_dict_train = {is_training_bn: True, \n",
    "                   use_moving_statistics:True,}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    acc = []\n",
    "    loss = []\n",
    "    for _ in range(steps_per_epoch_train):\n",
    "        \n",
    "        # get samples from the train set, with data augmentation \n",
    "        x, y =  iterator_train_aug.next()\n",
    "        feed_dict_train[batch_x] = x\n",
    "        feed_dict_train[batch_y] = y\n",
    "        feed_dict_train[learning_rate] = get_learning_rate(step, epoch, steps_per_epoch_train)\n",
    "        \n",
    "        acc_v, loss_v, _ = sess.run([acc_tf, loss_tf, train_op], feed_dict=feed_dict_train)\n",
    "        acc.append(acc_v)\n",
    "        loss.append(loss_v)\n",
    "        step += 1\n",
    "        \n",
    "    acc = np.mean(acc)\n",
    "    loss = np.mean(loss)\n",
    "    acc_train.append((epoch,acc))\n",
    "    loss_train.append((epoch,loss))\n",
    "    print(\"TRAIN @ EPOCH {} : acc={:.5f}  loss={:.5f}  in {:.3f} s\".format(epoch, acc, loss,\n",
    "                                                                               time()-start))\n",
    "    \n",
    "    acc, loss = inference(iterator_valid, with_moving_statistics=True)\n",
    "    acc_val.append((epoch,acc))\n",
    "    loss_val.append((epoch,loss))\n",
    "    print(\"VALID @ EPOCH {} : acc={:.5f}   loss={:.5f}  in {:.3f} s\".format(epoch, acc, loss,\n",
    "                                                                            time()-start))\n",
    "\n",
    "    # now fit batch norm statistics and make inference again \n",
    "    fit_bn_statistics()\n",
    "    acc, loss = inference(iterator_valid, with_moving_statistics=False)\n",
    "    acc_val_bn.append((epoch,acc))\n",
    "    loss_val_bn.append((epoch,loss))\n",
    "    print(\"VALID updated BN @ EPOCH {} : acc={:.5f}   loss={:.5f}  in {:.3f} s\".format(epoch, acc,\n",
    "                                                                                       loss, time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
