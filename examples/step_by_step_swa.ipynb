{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from math import ceil\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "EPOCHS_BEFORE_SWA = 5\n",
    "ALPHA1_LR = 0.1\n",
    "ALPHA2_LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "- load `train` and `test` subsets (CIFAR-10)\n",
    "- split `train` into `train` + `valid` (80/20%, stratified split on labels)\n",
    "\n",
    "- create data generators (with `keras.preprocessing.image.ImageDataGenerator`):\n",
    "    - one ImageDataGenerator with data augmentation (horizontal flips, random translations) for train set\n",
    "    - three ImageDataGenerator without data augmentation for train, valid and test subset \n",
    "        - why `train` ? : to fit Batch Norm statistics without augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading CIFAR10 dataset ...\n",
      "\tTRAIN - images (40000, 32, 32, 3) | float32  - labels (40000,) - int32\n",
      "\tVAL - images (10000, 32, 32, 3) | float32  - labels (10000,) - int32\n",
      "\tTEST - images (10000, 32, 32, 3) | float32  - labels (10000,) - int32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"... loading CIFAR10 dataset ...\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                                  test_size=0.2,\n",
    "                                                  stratify=y_train,\n",
    "                                                  random_state=51)\n",
    "# cast samples and labels\n",
    "x_train = x_train.astype(np.float32) / 255.\n",
    "x_val = x_val.astype(np.float32) / 255.\n",
    "x_test = x_test.astype(np.float32) / 255.\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_val = y_val.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "print(\"\\tTRAIN - images {} | {}  - labels {} - {}\".format(x_train.shape, x_train.dtype, y_train.shape, y_train.dtype))\n",
    "print(\"\\tVAL - images {} | {}  - labels {} - {}\".format(x_val.shape, x_val.dtype, y_val.shape, y_val.dtype))\n",
    "print(\"\\tTEST - images {} | {}  - labels {} - {}\\n\".format(x_test.shape, x_test.dtype, y_test.shape, y_test.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_aug = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=8, height_shift_range=8,\n",
    "                                                                fill_mode='constant', cval=0.0,\n",
    "                                                                horizontal_flip=True)\n",
    "\n",
    "generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# python iterator object that yields augmented samples \n",
    "iterator_train_aug = generator_aug.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "# python iterators object that yields not augmented samples \n",
    "iterator_train = generator.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "iterator_valid = generator.flow(x_val, y_val, batch_size=BATCH_SIZE)\n",
    "iterator_test = generator.flow(x_test, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (16, 32, 32, 3) | float32\n",
      "y : (16,) | int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f994b52ae10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test \n",
    "x, y = iterator_train_aug.next()\n",
    "img = x[0]*255\n",
    "print(\"x : {} | {}\".format(x.shape, x.dtype))\n",
    "print(\"y : {} | {}\".format(y.shape, y.dtype))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a network with MovingFreeBatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moving_free_batch_normalization import moving_free_batch_norm\n",
    "from stochastic_weight_averaging import StochasticWeightAveraging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs'):\n",
    "    batch_x = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32)\n",
    "    batch_y = tf.placeholder(shape=[None, ], dtype=tf.int64)\n",
    "    is_training_bn = tf.placeholder(shape=[], dtype=tf.bool)\n",
    "    use_moving_statistics = tf.placeholder(shape=[], dtype=tf.bool)\n",
    "    learning_rate = tf.placeholder(shape=[], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network similar to a VGG11 \n",
    "\n",
    "with tf.name_scope('network'):\n",
    "    x = tf.layers.conv2d(batch_x, filters=64, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2, data_format='channels_last', padding='same')\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=128, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2, data_format='channels_last', padding='same')\n",
    "    \n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=256, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn, use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.conv2d(x, filters=256, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2, data_format='channels_last', padding='same')\n",
    "    \n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=512, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn, use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.conv2d(x, filters=512, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2, data_format='channels_last', padding='same')\n",
    "    \n",
    "    \n",
    "    x = tf.layers.conv2d(x, filters=512, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn, use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    x = tf.layers.conv2d(x, filters=512, kernel_size=3, strides=1, use_bias=True,\n",
    "                         activation=tf.nn.relu, data_format='channels_last', padding='same')\n",
    "    x = moving_free_batch_norm(x, axis=-1, training=is_training_bn,\n",
    "                               use_moving_statistics=use_moving_statistics, momentum=0.99)\n",
    "    \n",
    "    # Global Average Pooling\n",
    "    x = tf.reduce_mean(x, axis=[1, 2]) \n",
    "    logits = tf.layers.dense(x, units=10, use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d/bias:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization/beta:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_1/bias:0' shape=(128,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_1/gamma:0' shape=(128,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_1/beta:0' shape=(128,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_2/bias:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_2/gamma:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_2/beta:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_3/bias:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_3/gamma:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_3/beta:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_4/bias:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_4/gamma:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_4/beta:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_5/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_5/bias:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_5/gamma:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_5/beta:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_6/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_6/bias:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_6/gamma:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_6/beta:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_7/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
      " <tf.Variable 'conv2d_7/bias:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_7/gamma:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'moving_free_batch_normalization_7/beta:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Variable 'dense/kernel:0' shape=(512, 10) dtype=float32_ref>,\n",
      " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "model_vars = tf.trainable_variables()\n",
    "pprint(model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'network/moving_free_batch_normalization/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_1/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_1/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_2/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_2/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_3/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_3/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_4/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_4/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_5/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_5/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_6/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_6/AssignMovingAvg_1' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_7/AssignMovingAvg' type=AssignSub>,\n",
      " <tf.Operation 'network/moving_free_batch_normalization_7/AssignMovingAvg_1' type=AssignSub>]\n",
      "[<tf.Tensor 'network/moving_free_batch_normalization/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_1/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_2/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_3/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_4/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_5/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_6/AssignAdd:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_7/AssignAdd:0' shape=() dtype=float32_ref>]\n",
      "[<tf.Tensor 'network/moving_free_batch_normalization/Assign:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization/Assign_1:0' shape=(64,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization/Assign_2:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_1/Assign:0' shape=(128,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_1/Assign_1:0' shape=(128,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_1/Assign_2:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_2/Assign:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_2/Assign_1:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_2/Assign_2:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_3/Assign:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_3/Assign_1:0' shape=(256,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_3/Assign_2:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_4/Assign:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_4/Assign_1:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_4/Assign_2:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_5/Assign:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_5/Assign_1:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_5/Assign_2:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_6/Assign:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_6/Assign_1:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_6/Assign_2:0' shape=() dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_7/Assign:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_7/Assign_1:0' shape=(512,) dtype=float32_ref>,\n",
      " <tf.Tensor 'network/moving_free_batch_normalization_7/Assign_2:0' shape=() dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "# operations to update moving averages in batch norm layers\n",
    "# to run before updating weights ! (with tf.control_dependencies())\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "# operations to updates (mean, variance, n) in batch norm layers \n",
    "update_bn_ops = tf.get_collection('UPDATE_BN_OPS')\n",
    "\n",
    "# operations to reset (mean, variance, n) to zero \n",
    "reset_bn_ops = tf.get_collection('RESET_BN_OPS')\n",
    "\n",
    "pprint(update_ops)\n",
    "pprint(update_bn_ops)\n",
    "pprint(reset_bn_ops)\n",
    "\n",
    "# group these operations\n",
    "update_ops = tf.group(*update_ops)\n",
    "update_bn_ops = tf.group(*update_bn_ops)\n",
    "reset_bn_ops = tf.group(*reset_bn_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    loss_tf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=batch_y))\n",
    "    acc_tf = tf.reduce_mean(tf.cast(tf.equal(batch_y, tf.argmax(logits, axis=1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    opt = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "    with tf.control_dependencies([update_ops,]):\n",
    "        train_op = opt.minimize(loss_tf, var_list=model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('SWA'):\n",
    "    swa = StochasticWeightAveraging()\n",
    "    swa_op = swa.apply(var_list=model_vars)\n",
    "    # Make backup variables\n",
    "    with tf.variable_scope('BackupVariables'):\n",
    "        backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\n",
    "                                       initializer=var.initialized_value())\n",
    "                       for var in model_vars]\n",
    "    # operation to assign SWA weights to model\n",
    "    swa_to_weights = tf.group(*(tf.assign(var, swa.average(var).read_value()) for var in model_vars))\n",
    "    # operation to store model into backup variables\n",
    "    save_weight_backups = tf.group(*(tf.assign(bck, var.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "    # operation to get back values from backup variables to model\n",
    "    restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value()) for var, bck in zip(model_vars, backup_vars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_init_op = tf.global_variables_initializer()\n",
    "sess.run(global_init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Learning rate policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(step, epoch, steps_per_epoch):\n",
    "    if epoch < EPOCHS_BEFORE_SWA:\n",
    "        return ALPHA1_LR\n",
    "\n",
    "    if step > int(0.9 * EPOCHS * steps_per_epoch):\n",
    "        return ALPHA2_LR\n",
    "\n",
    "    length_slope = int(0.9 * EPOCHS * steps_per_epoch) - EPOCHS_BEFORE_SWA * steps_per_epoch\n",
    "    re\n",
    "    return ALPHA1_LR - ((ALPHA1_LR - ALPHA2_LR) / length_slope) * (step - EPOCHS_BEFORE_SWA * steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98cd3ca7f0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps_per_epoch_train = iterator_train.n//BATCH_SIZE\n",
    "\n",
    "all_steps = []\n",
    "all_lr = []\n",
    "\n",
    "step = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for _ in range(steps_per_epoch_train):\n",
    "        all_steps.append(step)\n",
    "        all_lr.append(get_learning_rate(step, epoch, steps_per_epoch_train))\n",
    "        step += 1 \n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(all_steps, all_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch traninig \n",
    "- create a function to fit statistics with train subset\n",
    "- create a function to run inference on [train/]val/test subsets (with/without moving statistics\n",
    "- create a function to run inference with SWA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_train = int(ceil(iterator_train.n/BATCH_SIZE))\n",
    "steps_per_epoch_val = int(ceil(iterator_valid.n/BATCH_SIZE))\n",
    "steps_per_epoch_test = int(ceil(iterator_test.n/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_bn_statistics():\n",
    "    sess.run(reset_bn_ops)\n",
    "    \n",
    "    feed_dict = {is_training_bn: True, use_moving_statistics: True}\n",
    "    for _ in range(steps_per_epoch_train):\n",
    "        x, y = iterator_train.next()\n",
    "        feed_dict[batch_x] = x\n",
    "        sess.run(update_bn_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(iterator, with_moving_statistics=True):\n",
    "    feed_dict = {is_training_bn: False,\n",
    "                 use_moving_statistics: with_moving_statistics}\n",
    "    all_acc = []\n",
    "    all_loss = []\n",
    "    nb_steps = int(ceil(iterator.n/BATCH_SIZE))\n",
    "    \n",
    "    for _ in range(nb_steps):\n",
    "        x, y = iterator.next()\n",
    "        feed_dict[batch_x] = x\n",
    "        feed_dict[batch_y] = y\n",
    "        acc_v, loss_v = sess.run([acc_tf, loss_tf], feed_dict=feed_dict)\n",
    "        all_acc.append(acc_v)\n",
    "        all_loss.append(loss_v)\n",
    "    \n",
    "    return np.mean(all_acc), np.mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random model : acc=0.10000   loss=2.30249\n",
      "CPU times: user 21.8 s, sys: 8.88 s, total: 30.7 s\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test your random model ? \n",
    "acc, loss = inference(iterator_valid, with_moving_statistics=True)\n",
    "print(\"Random model : acc={:.5f}   loss={:.5f}\".format(acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random model : acc=0.09480   loss=2.53269\n",
      "CPU times: user 1min 39s, sys: 38.3 s, total: 2min 18s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# now fit batch norm statistics and make inference again \n",
    "fit_bn_statistics()\n",
    "acc, loss = inference(iterator_valid, with_moving_statistics=False)\n",
    "print(\"Random model : acc={:.5f}   loss={:.5f}\".format(acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_train = {is_training_bn: True, \n",
    "                   use_moving_statistics:True,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN @ EPOCH 0 : acc=0.33632  loss=1.80784  in 555.822 s\n",
      "VALID @ EPOCH 0 : acc=0.32030   loss=2.26033  in 585.007 s\n",
      "VALID updated bn @ EPOCH 0 : acc=0.43340   loss=1.51867  in 734.108 s\n",
      "TRAIN @ EPOCH 1 : acc=0.49085  loss=1.41674  in 1245.526 s\n",
      "VALID @ EPOCH 1 : acc=0.52660   loss=1.38642  in 1274.491 s\n",
      "VALID updated bn @ EPOCH 1 : acc=0.55820   loss=1.22307  in 1426.498 s\n",
      "TRAIN @ EPOCH 2 : acc=0.57248  loss=1.20919  in 1924.985 s\n",
      "VALID @ EPOCH 2 : acc=0.42920   loss=1.87827  in 1950.423 s\n",
      "VALID updated bn @ EPOCH 2 : acc=0.62640   loss=1.07354  in 2082.893 s\n",
      "TRAIN @ EPOCH 3 : acc=0.62680  loss=1.07984  in 2599.358 s\n",
      "VALID @ EPOCH 3 : acc=0.56520   loss=1.39566  in 2627.226 s\n",
      "VALID updated bn @ EPOCH 3 : acc=0.65010   loss=1.01985  in 2783.791 s\n",
      "TRAIN @ EPOCH 4 : acc=0.66347  loss=0.97796  in 3320.516 s\n",
      "VALID @ EPOCH 4 : acc=0.64350   loss=1.03858  in 3349.541 s\n",
      "VALID updated bn @ EPOCH 4 : acc=0.68600   loss=0.90761  in 3498.834 s\n",
      "TRAIN @ EPOCH 5 : acc=0.70213  loss=0.87313  in 4008.384 s\n",
      "VALID @ EPOCH 5 : acc=0.74610   loss=0.73422  in 4034.948 s\n",
      "VALID updated bn @ EPOCH 5 : acc=0.73470   loss=0.76876  in 4178.613 s\n",
      "TRAIN @ EPOCH 6 : acc=0.74235  loss=0.75533  in 4689.395 s\n",
      "VALID @ EPOCH 6 : acc=0.59010   loss=1.41301  in 4717.241 s\n",
      "VALID updated bn @ EPOCH 6 : acc=0.74260   loss=0.75759  in 4870.484 s\n",
      "VALID with SWA @ EPOCH 6 : acc=0.76910   loss=0.67760  in 5019.735 s\n",
      "TRAIN @ EPOCH 7 : acc=0.77425  loss=0.66192  in 5509.414 s\n",
      "VALID @ EPOCH 7 : acc=0.79820   loss=0.58907  in 5535.178 s\n",
      "VALID updated bn @ EPOCH 7 : acc=0.79040   loss=0.61905  in 5668.677 s\n",
      "VALID with SWA @ EPOCH 7 : acc=0.78510   loss=0.63085  in 5808.475 s\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "start = time()\n",
    "\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "\n",
    "acc_val = []\n",
    "loss_val = []\n",
    "\n",
    "acc_val_bn = []\n",
    "loss_val_bn = []\n",
    "\n",
    "acc_val_swa = []\n",
    "loss_val_swa = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    acc = []\n",
    "    loss = []\n",
    "    for _ in range(steps_per_epoch_train):\n",
    "        \n",
    "        feed_dict_train[learning_rate] = get_learning_rate(step, epoch, steps_per_epoch_train)\n",
    "        x, y =  iterator_train_aug.next()\n",
    "        feed_dict_train[batch_x] = x\n",
    "        feed_dict_train[batch_y] = y\n",
    "        \n",
    "        acc_v, loss_v, _ = sess.run([acc_tf, loss_tf, train_op], feed_dict=feed_dict_train)\n",
    "        acc.append(acc_v)\n",
    "        loss.append(loss_v)\n",
    "        step += 1\n",
    "        \n",
    "    acc = np.mean(acc)\n",
    "    loss = np.mean(loss)\n",
    "    acc_train.append((epoch,acc))\n",
    "    loss_train.append((epoch,loss))\n",
    "    print(\"TRAIN @ EPOCH {} : acc={:.5f}  loss={:.5f}  in {:.3f} s\".format(epoch, acc, loss,\n",
    "                                                                               time()-start))\n",
    "    \n",
    "    acc, loss = inference(iterator_valid, with_moving_statistics=True)\n",
    "    acc_val.append((epoch,acc))\n",
    "    loss_val.append((epoch,loss))\n",
    "    print(\"VALID @ EPOCH {} : acc={:.5f}   loss={:.5f}  in {:.3f} s\".format(epoch, acc, loss,\n",
    "                                                                            time()-start))\n",
    "\n",
    "    # now fit batch norm statistics and make inference again \n",
    "    fit_bn_statistics()\n",
    "    acc, loss = inference(iterator_valid, with_moving_statistics=False)\n",
    "    acc_val_bn.append((epoch,acc))\n",
    "    loss_val_bn.append((epoch,loss))\n",
    "    print(\"VALID updated bn @ EPOCH {} : acc={:.5f}   loss={:.5f}  in {:.3f} s\".format(epoch, acc,\n",
    "                                                                                       loss, time()-start))\n",
    "    \n",
    "    if epoch >= EPOCHS_BEFORE_SWA:\n",
    "        sess.run(swa_op)\n",
    "        \n",
    "    if epoch > EPOCHS_BEFORE_SWA:\n",
    "        sess.run(save_weight_backups)\n",
    "        sess.run(swa_to_weights)\n",
    "        \n",
    "        fit_bn_statistics()\n",
    "        acc, loss = inference(iterator_valid, with_moving_statistics=False)\n",
    "        acc_val_swa.append((epoch,acc))\n",
    "        loss_val_swa.append((epoch,loss))\n",
    "        print(\"VALID with SWA @ EPOCH {} : acc={:.5f}   loss={:.5f}  in {:.3f} s\".format(epoch, acc,\n",
    "                                                                                         loss, time()-start))\n",
    "        \n",
    "        sess.run(restore_weight_backups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
